# Advanced Memory Management

## 1. Thrashing

### What is Thrashing?

**Thrashing** = A situation where the system spends **more time paging** (swapping pages in/out) than **executing** actual processes.

### Simple Explanation
```
Normal System:
90% Execution + 10% Paging = Good Performance ✓

Thrashing System:
10% Execution + 90% Paging = Poor Performance ✗
System becomes extremely slow!
```

### Visual Representation
```
CPU Utilization vs Degree of Multiprogramming

CPU
Util  |         /\
 100% |        /  \
      |       /    \_____ Thrashing zone
      |      /          \___
      |     /                \___
      |    /                     \___
   0% |___/________________________\___
      0   1   2   3   4   5   6   7   8
          Degree of Multiprogramming
          
Optimal point: Maximum CPU utilization
After this: More processes = Thrashing
```

---

### How Thrashing Occurs

**Step-by-Step Process:**
```
1. System starts with few processes
   → CPU utilization low
   ↓
2. OS adds more processes (to increase utilization)
   → Each process gets fewer frames
   ↓
3. Processes don't have enough frames for working set
   → Page faults increase
   ↓
4. Page faults increase → More disk I/O
   → Processes spend time waiting
   ↓
5. CPU sees processes waiting → Adds MORE processes
   → Even fewer frames per process
   ↓
6. Page fault rate skyrockets
   → System spends all time paging
   ↓
7. THRASHING: System grinds to halt
```

### Example Scenario
```
System has: 100 frames
Process needs: 30 frames (working set)

3 Processes: 100/3 ≈ 33 frames each → OK ✓
4 Processes: 100/4 = 25 frames each → Page faults increase ✗
5 Processes: 100/5 = 20 frames each → Heavy paging ✗✗
10 Processes: 100/10 = 10 frames each → THRASHING! ✗✗✗
```

---

### Causes of Thrashing

**1. Too Many Processes (High Degree of Multiprogramming)**
- System tries to run more processes than memory can support
- Each process gets insufficient frames

**2. Insufficient Frames per Process**
- Process working set doesn't fit in allocated frames
- Constant page faults

**3. Poor Page Replacement Algorithm**
- Wrong pages get replaced
- Needed pages keep getting swapped out

**4. Lack of Working Set Management**
- System doesn't consider process working set size
- Allocates frames arbitrarily

**5. Global Page Replacement**
- One process's page faults affect others
- Cascading effect

---

### Effects of Thrashing

**1. Severe Performance Degradation**
```
Normal: Task completes in 10 seconds
Thrashing: Same task takes 10 minutes!
```

**2. Low CPU Utilization**
```
CPU mostly idle waiting for page I/O
CPU utilization drops below 10%
```

**3. High Disk Activity**
```
Disk constantly seeking, reading, writing pages
Disk LED constantly blinking
```

**4. System Unresponsiveness**
```
Mouse/keyboard inputs delayed
Applications freeze
System appears "hung"
```

**5. Process Starvation**
```
No process makes progress
All stuck in page fault loops
```

---

### Prevention of Thrashing

### 1. Local Page Replacement
**Concept:** Each process can only replace its **own pages**
```
Global Replacement:
Process A faults → Replaces page from Process B
→ Process B faults → Replaces from C
→ Cascading failures → Thrashing

Local Replacement:
Process A faults → Replaces only its own page
→ Other processes unaffected
→ Limits damage ✓
```

**Advantage:** Prevents one process from affecting others
**Disadvantage:** Less flexible memory allocation

---

### 2. Working Set Model
**Concept:** Ensure each process has **enough frames** for its working set
```
Working Set Size = Pages needed for current execution phase

Allocation Rule:
If (Total Working Set Size) ≤ Available Frames:
    → Run all processes ✓
Else:
    → Suspend some processes ✓
    → Prevent thrashing
```

**Example:**
```
Process A working set: 30 frames
Process B working set: 25 frames
Process C working set: 40 frames
Total: 95 frames needed

Available frames: 100
→ Run all 3 processes ✓

Available frames: 80
→ Suspend Process C (largest)
→ Run only A and B ✓
```

---

### 3. Page Fault Frequency (PFF) Scheme

**Concept:** Monitor page fault rate and adjust frame allocation
```
PFF Scheme:

Upper Threshold (e.g., 10 faults/second)
Lower Threshold (e.g., 2 faults/second)

If (Page Fault Rate > Upper Threshold):
    → Give MORE frames to process
Else If (Page Fault Rate < Lower Threshold):
    → Take away frames from process
```

**Visual:**
```
Page
Fault  |
Rate   |     ↗ Too many faults
       |    /   → Allocate more frames
Upper -|---/----
       |  /
       | /
Lower -|/--------
       |         ↘ Too few faults
       |           → Reduce frames
       |________________________________
              Time
```

**Example:**
```
Process X: 15 faults/sec → Above upper threshold
Action: Increase frames from 20 to 30

Process Y: 1 fault/sec → Below lower threshold
Action: Reduce frames from 25 to 20
```

---

### 4. Suspend Processes (Load Control)

**Concept:** Reduce degree of multiprogramming
```
Medium-Term Scheduler:

If (Thrashing Detected):
    1. Swap out some processes completely
    2. Free up their frames
    3. Remaining processes get more frames
    4. Resume processes when memory available
```

**Example:**
```
Before: 10 processes, each with 10 frames → Thrashing
After: Suspend 4 processes
       6 processes, each with ~17 frames → Normal
```

---

### 5. Increase Physical Memory (Hardware Solution)

**Simple but Effective:**
```
More RAM → More frames → Larger working sets fit
→ Less paging → No thrashing ✓

Example:
Old: 2 GB RAM → Thrashing with 10 processes
New: 8 GB RAM → No thrashing with 20 processes
```

---

### 6. Improve Locality of Programs

**Programmer Optimization:**
```
Poor Locality Code:
for i in range(1000):
    for j in range(1000):
        access array[j][i]  # Column-major (cache misses)

Good Locality Code:
for i in range(1000):
    for j in range(1000):
        access array[i][j]  # Row-major (cache hits)
```

---

## 2. Locality of Reference

### What is Locality of Reference?

**Locality of Reference** = Tendency of a process to access a **small set of memory locations** repeatedly over a short period of time.

### Why Locality Matters
```
With Locality:
- Pages needed are predictable
- Fewer page faults
- Better cache performance
- Virtual memory works well ✓

Without Locality:
- Random memory access
- Frequent page faults
- Poor cache performance
- Thrashing risk ✗
```

---

### Types of Locality

### 1. Temporal Locality (Time-based)

**Definition:** If a memory location is accessed, it is **likely to be accessed again soon**

**Principle:** "Recently accessed items will be accessed again"

**Examples:**

**Example 1: Loop Variables**
```c
for (int i = 0; i < 1000; i++) {
    sum += array[i];
}
// Variable 'i' accessed repeatedly (temporal locality)
// Variable 'sum' accessed repeatedly
```

**Example 2: Function Calls**
```c
void calculateTotal() {
    // This function called multiple times
    // Code here has temporal locality
}

calculateTotal();  // Call 1
calculateTotal();  // Call 2
calculateTotal();  // Call 3
```

**Example 3: Stack Operations**
```
Function calls use stack repeatedly
Push/Pop operations access same stack top
→ High temporal locality
```

---

### 2. Spatial Locality (Space-based)

**Definition:** If a memory location is accessed, **nearby locations** are likely to be accessed soon

**Principle:** "Items close to recently accessed items will be accessed"

**Examples:**

**Example 1: Array Traversal**
```c
int array[100];
for (int i = 0; i < 100; i++) {
    process(array[i]);  // Accesses sequential locations
}
// array[0], array[1], array[2]... are nearby
// High spatial locality
```

**Example 2: Sequential Code Execution**
```
Instruction Address:
1000: LOAD A
1004: ADD B      ← Next instruction nearby
1008: STORE C    ← Next instruction nearby
1012: JUMP X

Instructions stored sequentially → Spatial locality
```

**Example 3: Struct Members**
```c
struct Student {
    int id;        // Address: 1000
    char name[20]; // Address: 1004
    float grade;   // Address: 1024
};

student.id;     // Access 1000
student.name;   // Access 1004 (nearby)
student.grade;  // Access 1024 (nearby)
```

---

### Comparison: Temporal vs Spatial

| Aspect | Temporal Locality | Spatial Locality |
|--------|-------------------|------------------|
| **Based on** | Time (when) | Space (where) |
| **Principle** | Recently used → Used again | Nearby locations accessed |
| **Example** | Loop counter | Array elements |
| **Cache** | Keep recent items | Fetch blocks of data |
| **Benefit** | Reuse data | Prefetch nearby data |

---

### Combined Example
```c
// Program demonstrating BOTH localities

int sum = 0;  // Temporal: 'sum' used repeatedly

for (int i = 0; i < 100; i++) {  // Temporal: 'i' used repeatedly
    sum += array[i];  // Spatial: array elements sequential
}

Analysis:
- 'sum': Temporal locality (accessed every iteration)
- 'i': Temporal locality (accessed every iteration)
- array[i]: Spatial locality (sequential access)
- Loop code: Spatial locality (instructions sequential)
```

---

### How Virtual Memory Exploits Locality

**Working Set Concept:**
```
Process exhibits locality
→ Uses small set of pages at any time (working set)
→ Keep working set in memory
→ Most references hit in memory ✓
→ Few page faults ✓
```

**Without Locality:**
```
Random access pattern
→ No predictable working set
→ Constant page faults
→ Thrashing ✗
```

---

### Measuring Locality

**Good Locality Indicators:**
- Sequential access patterns
- Nested loops accessing same data
- Small working set size
- Low page fault rate
- High cache hit rate

**Poor Locality Indicators:**
- Random access patterns
- Large working set
- Frequent page faults
- Low cache hit rate
- Scattered memory references

---

## 3. Working Set Model

### What is Working Set?

**Working Set** = Set of pages that a process is **currently using** (actively referencing)

**Formal Definition:**
Working Set W(t,Δ) = Set of pages referenced in the **last Δ time units** (or references)
```
Working Set = {Pages accessed in recent window}

Window Size (Δ):
- Too small → Doesn't capture full locality
- Too large → Includes unnecessary pages
- Typical: 10,000 - 100,000 references
```

---

### Working Set Model Concept
```
Time Windows:
┌───────────────────────────────────────┐
│ t₁    t₂    t₃    t₄    t₅    t₆    t₇│
└───────────────────────────────────────┘
  ↑           ↑
  └───Δ──────┘  Working Set Window

Pages referenced in this window = Working Set
```

### Example: Working Set Calculation

**Reference String:** 1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5
**Window Size (Δ):** 5 references
```
Position  Last 5 Refs    Working Set        Size
--------  -----------    ---------------    ----
5         1,2,3,4,1      {1,2,3,4}          4
6         2,3,4,1,2      {1,2,3,4}          4
7         3,4,1,2,5      {1,2,3,4,5}        5
8         4,1,2,5,1      {1,2,4,5}          4
9         1,2,5,1,2      {1,2,5}            3
10        2,5,1,2,3      {1,2,3,5}          4
11        5,1,2,3,4      {1,2,3,4,5}        5
12        1,2,3,4,5      {1,2,3,4,5}        5
```

**Working Set Size varies:** 3 to 5 pages

---

### Working Set Properties

**1. Size Changes Over Time**
```
Initialization Phase: WS grows (loading new pages)
Steady State: WS relatively stable
Phase Change: WS changes (new execution phase)
```

**2. Reflects Locality**
```
Good locality → Small, stable working set
Poor locality → Large, changing working set
```

**3. Program Phases**
```
Phase 1 (Initialization):
WS = {Pages for startup code}

Phase 2 (Main Loop):
WS = {Pages for loop code + data}

Phase 3 (I/O):
WS = {Pages for I/O routines}
```

---

### Working Set Model for Multiprogramming

**Key Decision Rule:**
```
Let:
WSᵢ = Working set size of process i
m = Total available frames

Rule:
If Σ(WSᵢ) ≤ m:
    → Run all processes ✓
Else:
    → Suspend some processes
    → Run subset where Σ(WS) ≤ m
```

### Example: Process Scheduling Decision
```
System Memory: 100 frames

Process A: WS = 30 frames
Process B: WS = 25 frames
Process C: WS = 20 frames
Process D: WS = 35 frames

Total: 30 + 25 + 20 + 35 = 110 frames

Decision:
110 > 100 → Cannot run all
Suspend D (largest WS = 35)
Run A, B, C: 30 + 25 + 20 = 75 ≤ 100 ✓
```

---

### Page Fault Frequency vs Working Set
```
Page Faults Over Time:

Faults |     ╱╲     ╱╲
       |    ╱  ╲   ╱  ╲
       |   ╱    ╲ ╱    ╲
       |__╱______╲╱______╲_____
          Phase  Phase  Phase
          Change Change Change
          
Working set changes → Page faults increase
Working set stable → Page faults decrease
```

---

### Working Set Algorithm

**Page Replacement based on Working Set:**
```
When page fault occurs:

1. Find page NOT in working set (outside window Δ)
2. Replace that page
3. If all pages in working set:
   - Use additional algorithm (LRU, FIFO)
```

**Example:**
```
Current time: t = 1000
Window: Δ = 100 references
Working Set: Pages accessed from t=900 to t=1000

Pages in memory:
Page A: Last access = 950 → In WS (keep)
Page B: Last access = 850 → NOT in WS (replace) ✓
Page C: Last access = 980 → In WS (keep)
Page D: Last access = 920 → In WS (keep)

Replace Page B
```

---

### Advantages of Working Set Model

✓ **Prevents Thrashing**
- Ensures sufficient frames for working set
- No process runs without enough memory

✓ **Better Multiprogramming**
- Smart admission control
- Balance between too many/few processes

✓ **Reflects Program Behavior**
- Based on actual usage patterns
- Adapts to program phases

✓ **Optimal Frame Allocation**
- Processes get what they need
- No waste, no shortage

---

### Disadvantages of Working Set Model

✗ **Overhead**
- Need to track page references in time window
- Complex bookkeeping

✗ **Difficult to Implement**
- Hard to determine optimal Δ
- Requires sophisticated tracking

✗ **Memory for Tracking**
- Need data structures to track working set
- Additional memory overhead

---

### Working Set vs Page Fault Frequency

| Working Set Model | Page Fault Frequency |
|-------------------|---------------------|
| Proactive (predict needs) | Reactive (respond to faults) |
| Track reference history | Monitor fault rate |
| Complex implementation | Simpler implementation |
| Better prevention | Good correction |
| Higher overhead | Lower overhead |

**Best Approach:** Combine both
- Use working set for admission control
- Use PFF for dynamic adjustment

---
